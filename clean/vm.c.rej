--- vm.c	(revision 3)
+++ vm.c	(working copy)
@@ -6,11 +6,16 @@
 #include "mmu.h"
 #include "proc.h"
 #include "elf.h"
+#include "spinlock.h"
 
 extern char data[];  // defined by kernel.ld
 pde_t *kpgdir;  // for use in scheduler()
 struct segdesc gdt[NSEGS];
 
+//task4
+struct spinlock num_of_shareslock;
+uchar num_of_shares[PHYSTOP/PGSIZE]; // counter for the number of shares per page
+
 // Set up CPU's kernel segment descriptors.
 // Run once on entry on each CPU.
 void
@@ -28,7 +33,7 @@
   c->gdt[SEG_UCODE] = SEG(STA_X|STA_R, 0, 0xffffffff, DPL_USER);
   c->gdt[SEG_UDATA] = SEG(STA_W, 0, 0xffffffff, DPL_USER);
 
-  // Map cpu, and curproc
+//   // Map cpu, and curproc
   c->gdt[SEG_KCPU] = SEG(STA_W, &c->cpu, 8, 0);
 
   lgdt(c->gdt, sizeof(c->gdt));
@@ -37,6 +42,8 @@
   // Initialize cpu-local storage.
   cpu = c;
   proc = 0;
+  
+  initlock(&num_of_shareslock, "sharedLock");
 }
 
 // Return the address of the PTE in page table pgdir
@@ -47,7 +54,8 @@
 {
   pde_t *pde;
   pte_t *pgtab;
-
+  
+  //PDX - entry that the 10 first bits points to.
   pde = &pgdir[PDX(va)];
   if(*pde & PTE_P){
     pgtab = (pte_t*)p2v(PTE_ADDR(*pde));
@@ -80,6 +88,8 @@
       return -1;
     if(*pte & PTE_P)
       panic("remap");
+    
+    
     *pte = pa | perm | PTE_P;
     if(a == last)
       break;
@@ -137,8 +147,7 @@
   if (p2v(PHYSTOP) > (void*)DEVSPACE)
     panic("PHYSTOP too high");
   for(k = kmap; k < &kmap[NELEM(kmap)]; k++)
-    if(mappages(pgdir, k->virt, k->phys_end - k->phys_start, 
-                (uint)k->phys_start, k->perm) < 0)
+    if(mappages(pgdir, k->virt, k->phys_end - k->phys_start, (uint)k->phys_start, k->perm) < 0)
       return 0;
   return pgdir;
 }
@@ -194,17 +203,23 @@
 // Load a program segment into pgdir.  addr must be page-aligned
 // and the pages from addr to addr+sz must already be mapped.
 int
-loaduvm(pde_t *pgdir, char *addr, struct inode *ip, uint offset, uint sz)
+loaduvm(pde_t *pgdir, char *addr, struct inode *ip, uint offset, uint sz,uint writeFlag)
 {
   uint i, pa, n;
   pte_t *pte;
-
-  if((uint) addr % PGSIZE != 0)
-    panic("loaduvm: addr must be page aligned");
-  for(i = 0; i < sz; i += PGSIZE){
+  
+  //if((uint) addr % PGSIZE != 0)
+    //panic("loaduvm: addr must be page aligned");
+  for(i = 0; i < sz; i += PGSIZE) {
     if((pte = walkpgdir(pgdir, addr+i, 0)) == 0)
       panic("loaduvm: address should exist");
-    pa = PTE_ADDR(*pte);
+
+    if (writeFlag)		//task3 , set writable flag as ELF instructed
+    	*pte |= PTE_W;
+    else
+    	*pte &= ~PTE_W;
+    pa = PTE_ADDR(*pte) + ((uint)(addr)%PGSIZE); //task3, add padding for page alignment
+
     if(sz - i < PGSIZE)
       n = sz - i;
     else
@@ -217,6 +232,7 @@
 
 // Allocate page tables and physical memory to grow process from oldsz to
 // newsz, which need not be page aligned.  Returns new size or 0 on error.
+//allocuvm(pde_t *pgdir, uint oldsz, uint newsz, uint writeFlag)
 int
 allocuvm(pde_t *pgdir, uint oldsz, uint newsz)
 {
@@ -237,7 +253,9 @@
       return 0;
     }
     memset(mem, 0, PGSIZE);
+
     mappages(pgdir, (char*)a, PGSIZE, v2p(mem), PTE_W|PTE_U);
+
   }
   return newsz;
 }
@@ -257,16 +275,22 @@
 
   a = PGROUNDUP(newsz);
   for(; a  < oldsz; a += PGSIZE){
-    pte = walkpgdir(pgdir, (char*)a, 0);
-    if(!pte)
-      a += (NPTENTRIES - 1) * PGSIZE;
-    else if((*pte & PTE_P) != 0){
-      pa = PTE_ADDR(*pte);
-      if(pa == 0)
-        panic("kfree");
-      char *v = p2v(pa);
-      kfree(v);
-      *pte = 0;
+	  pte = walkpgdir(pgdir, (char*)a, 0);
+	  if(!pte)
+		  a += (NPTENTRIES - 1) * PGSIZE;
+	  else if((*pte & PTE_P) != 0) {
+		  pa = PTE_ADDR(*pte);
+		  if(pa == 0)
+			  panic("kfree");
+		  acquire(&num_of_shareslock);
+		  if (num_of_shares[pa/PGSIZE] == 0) {
+			  char *v = p2v(pa);
+			  kfree(v);
+		  } else
+			  num_of_shares[pa/PGSIZE]--;
+
+		  release(&num_of_shareslock);
+		  *pte = 0;
     }
   }
   return newsz;
@@ -304,11 +328,11 @@
   *pte &= ~PTE_U;
 }
 
+
 // Given a parent process's page table, create a copy
 // of it for a child.
 pde_t*
-copyuvm(pde_t *pgdir, uint sz)
-{
+copyuvm(pde_t *pgdir, uint sz) {
   pde_t *d;
   pte_t *pte;
   uint pa, i;
@@ -315,19 +339,131 @@
   char *mem;
 
   if((d = setupkvm()) == 0)
+  return 0;
+  for(i = PGSIZE; i < sz; i += PGSIZE){
+	  if((pte = walkpgdir(pgdir, (void *) i, 0)) == 0)
+		  panic("copyuvm: pte should exist");
+	  if(!(*pte & PTE_P))
+		  panic("copyuvm: page not present");
+	  pa = PTE_ADDR(*pte);
+	  if((mem = kalloc()) == 0)
+		  goto bad;
+	  memmove(mem, (char*)p2v(pa), PGSIZE); // copy data
+	  //task3, copy to child the same flags as the father
+	  if (*pte & PTE_W) {
+		  if(mappages(d, (void*)i, PGSIZE, v2p(mem), PTE_W|PTE_U) < 0)
+			  goto bad;
+	  } else {
+		  if(mappages(d, (void*)i, PGSIZE, v2p(mem), PTE_U) < 0)
+			  goto bad;
+	  }
+  }
+  return d;
+  
+bad:
+  freevm(d);
+  return 0;
+}
+
+void
+handle_pgflt(void)
+{
+  char *mem;
+  pte_t *pte;
+  uint pa;
+  
+  uint faultingAddress = read_cr2();
+
+  if (faultingAddress==0) {
+    cprintf("NULL POINTER EXCEPTION! kill&exit\n");
+    proc->killed = 1;
+    exit();
+  }
+  
+  if ((pte = walkpgdir(proc->pgdir, (void*)faultingAddress , 0)) == 0)
+    panic("handle_pgflt: pte should exist");
+  if(!(*pte & PTE_P))
+      panic("handle_pgflt: page not present");
+  
+  pa = PTE_ADDR(*pte);
+
+  acquire(&num_of_shareslock);
+  
+  // case1: the process who enters is the last one between the process who share this page
+  if ((num_of_shares[pa/PGSIZE] == 0) && ((*pte)& PTE_WAS_WRITABLE)) {
+    *pte &= ~PTE_SH;  // disable Sharing for this page
+    *pte &= ~PTE_WAS_WRITABLE;  // no need for the ORIGINALLY writable flag
+    *pte |= PTE_W;	// update to writable
+    goto finish_hadle_pgflt;
+  }
+  
+  // case2: some process enters
+  if ((num_of_shares[pa/PGSIZE] > 0) && ((*pte)&PTE_WAS_WRITABLE) && ((*pte)&PTE_SH)) {
+    num_of_shares[pa >> PGSHIFT]--;  //update counter
+    if((mem = kalloc()) == 0)		// allocate memory
+    	panic("handle_pgflt: failed to kalloc");
+    memmove(mem, (char*)p2v(pa), PGSIZE);  // move data to allocated memory
+    *pte &= ~PTE_SH;	// mark as Not shared (because just copied for this process use only)
+    *pte &= ~PTE_WAS_WRITABLE;	// ORIGINALLY writable not relevant anymore
+    *pte = (*pte & 0XFFF) | v2p(mem) | PTE_W;	// update entry & writable flag
+    goto finish_hadle_pgflt;
+  }
+  
+  // case3: process trying to write to ORIGINALLY read-only page
+  if (!((*pte)&PTE_WAS_WRITABLE)) {
+      cprintf("ACCESS VIOLATION! tried to write to read-only page. kill&exit\n");
+      release(&num_of_shareslock);
+      proc->killed = 1;
+      exit(); 
+  }
+
+  
+finish_hadle_pgflt:
+  release(&num_of_shareslock);
+  flush_tlb_all();
+}
+
+
+// Given a parent process's page table, 
+pde_t*
+copyuvm_cow(pde_t *pgdir, uint sz) {
+  pde_t *d;
+  pte_t *pte;
+  uint i, pa, flags;
+  
+  if((d = setupkvm()) == 0)
     return 0;
-  for(i = 0; i < sz; i += PGSIZE){
-    if((pte = walkpgdir(pgdir, (void *) i, 0)) == 0)
-      panic("copyuvm: pte should exist");
-    if(!(*pte & PTE_P))
-      panic("copyuvm: page not present");
-    pa = PTE_ADDR(*pte);
-    if((mem = kalloc()) == 0)
-      goto bad;
-    memmove(mem, (char*)p2v(pa), PGSIZE);
-    if(mappages(d, (void*)i, PGSIZE, v2p(mem), PTE_W|PTE_U) < 0)
-      goto bad;
+
+  for(i = PGSIZE; i < sz; i += PGSIZE) {
+	  if((pte = walkpgdir(pgdir, (void *) i, 0)) == 0)
+		  panic("copyuvm_cow: pte should exist");
+	  if(!(*pte & PTE_P))
+		  panic("copyuvm_cow: page not present");
+   
+	  pa = PTE_ADDR(*pte);
+    
+	  acquire(&num_of_shareslock);
+	  num_of_shares[pa/PGSIZE]++;  // counter for num of shares
+	  release(&num_of_shareslock);
+    
+	  flags =  *pte & 0xfff;
+	  if ((flags & PTE_W ) | (flags & PTE_WAS_WRITABLE)) {
+		  flags &= ~PTE_W;		// marking page as read-only
+		  flags |= PTE_SH ;		// and shared
+		  flags |= PTE_WAS_WRITABLE; // and that it was ORIGINALY writable for later identification
+		  if (mappages(d, (void*)i, PGSIZE, pa, flags) < 0)
+			  goto bad;
+	  } else {
+		  flags |= PTE_SH;	// keep the page readony and mark it as Shared
+		  if (mappages(d, (void*)i, PGSIZE, pa, flags) < 0)
+			  goto bad;
+	  }
+    
+	  *pte = (*pte & ~0xfff) | flags; // update flags
+     
   }
+  
+  flush_tlb_all();
   return d;
 
 bad:
